プログラムについての説明

master.pyを起動すると、最初に表情の撮影モード(my_capture関数)が始まる。
sを押すことで撮影がスタート。
現在は、五種類の表情（c_faceを直接編集可）を適当に用意しています。
5秒間隔（gap）で撮影しています。
撮影した画像は、outputフォルダの中に
timestamp(y-m-d_H-M-S)/expression_name.png
で5つ保存される。
（saitoのプログラムと同期するため、同期用のフォルダに保存する必要がある）

基本的に、処理はすべて赤枠の中の画像データを用いて行う。
この赤枠のサイズは、調整の必要があるが、あまり大きくすると精度とスピードに影響が。


顔の撮影モードは、qを押すことでスキップができるが、本来はいらない機能。

顔の撮影が終わると、絵文字検出モード（main関数）が始まる。
main()では、最初に画面全体のframeからimg2という赤枠部分を取り出している。
赤枠部分を切り取ったのち、detect関数にimg2を渡す。
detect()では、img2と検索画像ファイル（faces, img2フォルダ内）を各々比較し、
特徴量検出アルゴリズム(AKAZE)によって表情detectionをしている。
そのため、テンプレートの画像数によって計算時間が大幅に変わってきます。
現在は8つの絵文字を入れていますが、最終的には5,6個に絞ります。

AKAZEアルゴリズムに関して、ratioというパラメータを小さくすると、特徴点の検索が厳しくなる。
また、139行のlen(good)は特徴点一致の個数を表していて、現在のコードでは3個を閾値として設定している。

ちなみに、今はdetect関数は0.5秒おきに実行しており、この秒数もチューニングの必要があると思われます。
detectで絵文字が発見された場合、その発見された回数をdetected_countsに格納しています。
（順番は、facesの順番と同じです。）
今はただカウントするだけのプログラムですが、そのカウントを利用し、returnで表情を返すようにするといいと思います。


裏の検出に関して
裏の特徴が全然ないので、hsv空間での黄色成分の量に対して閾値を設けています。

detect関数で表情が検出できない&&黄色成分がたくさんある -> 裏が写っている

という仕組みです。（現在はピクセル数の閾値を60000に設定しています）

そして、裏判定が連続で何回出ているかをura_countで記憶しています。
ura_countを引数としてdisplay_face関数に渡すことで、カメラの映像のなかに
最初に撮影した顔がura_countの大きさに応じて映り込む仕組みです。
（RGB空間で内分点を取っています）


プログラムを終了したいときは、windowを選択して「q」を押してください。


以上でプログラムの説明になります。
なにかわからないことがあれば質問してください。
